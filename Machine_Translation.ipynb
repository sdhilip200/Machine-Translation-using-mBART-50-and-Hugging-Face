{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English_to_Tamil_Hindi_Translation_with_Hugging_Face_ü§ó_and_MBart.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdhilip200/Machine-Translation-using-mBART-50-and-Hugging-Face/blob/main/Machine_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeRnQMaWO-_5"
      },
      "source": [
        "## **Installing Transformer library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RtEvp3Me4va",
        "outputId": "c3cb53e9-da0f-4016-f149-13608cb63842"
      },
      "source": [
        "# Installing transformer\n",
        "\n",
        "!pip install -q transformers\n",
        "!pip install -q sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.0MB 10.1MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 890kB 53.7MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.2MB 52.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2MB 9.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVvBUv9UREVI"
      },
      "source": [
        "# SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. For more details please check this [Github](https://github.com/google/sentencepiece)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meoiWtmhTtWE"
      },
      "source": [
        "## **Importing classes MBART Conditional Generation and Mbart50 Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqfrTUTvPKkA"
      },
      "source": [
        "# Importing the mBART functions from transformer library\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANgmdSa9UJaI"
      },
      "source": [
        "MBart-50 has its own tokenizer MBart50Tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2euOFb9PKp6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8Gn4nEV66GE"
      },
      "source": [
        "I am going to translate English to Tamil and English to French Let's start with English to Tamil first. Before that we need to download the mBART 50 and the tokenizer model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZITxKPSXUrP"
      },
      "source": [
        "## **Downloading the mBART 50 model and the tokenizer**\n",
        "\n",
        "We are using mBART large 50 many to many model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJqUwL3JPKtZ"
      },
      "source": [
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\", src_lang=\"en_XX\")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANm-5IKr7Row"
      },
      "source": [
        "Here, src_lang is a source language. We are translating english to tamil, hence our source langauge is english. mBART 50 supports 50 different lanagauges. It supports many regional indian languages. For more information, you can check the [documentation ](https://huggingface.co/facebook/mbart-large-50-many-to-many-mmt)and code has been given for the each langauge. Using en_XX for English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mqJLyp4eZaj"
      },
      "source": [
        "# Sample text to translate into tamil\n",
        "\n",
        "text = \"Bhutan begins biggest vaccination drive against Covid-19\""
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSwo-VQkGitj"
      },
      "source": [
        "Giving the sample text into tokenizer and assigned to model_inputs variable. Also, we can specify whether we need pytorch tensor (pt) or tensorflow tensor. Here, I specified pytorch tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzj93gO7f0Gc"
      },
      "source": [
        "model_inputs = tokenizer(text, return_tensors = \"pt\")\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg-JZDnCH0Az"
      },
      "source": [
        "Next step is to generate the tokens. We have model input and need to specify which language we need to translate. Here, we are traslating into Tamil, so it is \"ta_IN\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAPso02IfehL"
      },
      "source": [
        "# English to Tamil translation\n",
        "generated_tokens = model.generate(**model_inputs, forced_bos_token_id = tokenizer.lang_code_to_id [\"ta_IN\"])\n",
        "\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_dD4j3-IUOb"
      },
      "source": [
        "Now we can decode the tokens using tokenizer decode.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNRp5-dMfoiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c0fa62-e2e1-44f8-a765-2c3957791ddf"
      },
      "source": [
        "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "translation"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['‡Æï‡Øã‡Æµ‡Æø‡Æü‡Øç-19-‡Æï‡Øç‡Æï‡ØÅ ‡Æé‡Æ§‡Æø‡Æ∞‡Ææ‡Æ© ‡ÆÆ‡Æø‡Æï‡Æ™‡Øç‡Æ™‡ØÜ‡Æ∞‡Æø‡ÆØ ‡Æ§‡Æü‡ØÅ‡Æ™‡Øç‡Æ™‡ØÇ‡Æö‡Æø ‡Æá‡ÆØ‡Æï‡Øç‡Æï‡Æ§‡Øç‡Æ§‡Øà ‡Æ™‡ØÇ‡Æü‡Øç‡Æü‡Ææ‡Æ©‡Øç ‡Æ§‡Øä‡Æü‡Æô‡Øç‡Æï‡Æø‡ÆØ‡Æ§‡ØÅ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8-r8uAeI2h2"
      },
      "source": [
        "## **English to French Translation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VGDlKnEgGKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "004a93ff-e628-4e90-d4e7-85511e51efae"
      },
      "source": [
        "sample = \"Bhutan begins biggest vaccination drive against Covid-19\"\n",
        "model_inputs = tokenizer(sample, return_tensors = \"pt\")\n",
        "# Changing the language into french and using the code \"fr_XX\"\n",
        "generated_tokens = model.generate(**model_inputs, forced_bos_token_id = tokenizer.lang_code_to_id [\"fr_XX\"])\n",
        "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "translation"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Le Bhoutan amorce la plus importante campagne de vaccination contre le Covid-19']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTfbracbMfZC"
      },
      "source": [
        "Seems, the model did a pretty good job. Let's check the above examples with Google Translate. Both the results are nearly equal. It seems the model did a pretty decent job here. We can change the input to 50 different lanuages and translate. You can check the documentation for the more language code and try yourself. You can also try with long texts and see how it performs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAICaveSMMim"
      },
      "source": [
        "Both the results are nearly equal. It seems the model did a pretty decent job here. We can change the input to 50 different lanuages and translate. You can check the documentation for the more language code and try yourself. You can also try with long texts and see how it performs. "
      ]
    }
  ]
}